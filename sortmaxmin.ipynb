{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tx/xsb7n6wx3m3_hgtjstktffs80000gn/T/ipykernel_84425/1977979249.py:4: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  data = pd.read_csv(\"./data/dsc_fc_summed_spectra_2020_v01.csv\", \\\n",
      "/var/folders/tx/xsb7n6wx3m3_hgtjstktffs80000gn/T/ipykernel_84425/1977979249.py:9: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  label1 = pd.read_csv(\"./data/2020Q1_DGD.csv\", \\\n",
      "/var/folders/tx/xsb7n6wx3m3_hgtjstktffs80000gn/T/ipykernel_84425/1977979249.py:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  label1 = pd.read_csv(\"./data/2020Q1_DGD.csv\", \\\n",
      "/var/folders/tx/xsb7n6wx3m3_hgtjstktffs80000gn/T/ipykernel_84425/1977979249.py:14: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  label2 = pd.read_csv(\"./data/2020Q2_DGD.csv\", \\\n",
      "/var/folders/tx/xsb7n6wx3m3_hgtjstktffs80000gn/T/ipykernel_84425/1977979249.py:14: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  label2 = pd.read_csv(\"./data/2020Q2_DGD.csv\", \\\n",
      "/var/folders/tx/xsb7n6wx3m3_hgtjstktffs80000gn/T/ipykernel_84425/1977979249.py:19: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  label3 = pd.read_csv(\"./data/2020Q3_DGD.csv\", \\\n",
      "/var/folders/tx/xsb7n6wx3m3_hgtjstktffs80000gn/T/ipykernel_84425/1977979249.py:19: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  label3 = pd.read_csv(\"./data/2020Q3_DGD.csv\", \\\n",
      "/var/folders/tx/xsb7n6wx3m3_hgtjstktffs80000gn/T/ipykernel_84425/1977979249.py:24: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  label4 = pd.read_csv(\"./data/2020Q4_DGD.csv\", \\\n",
      "/var/folders/tx/xsb7n6wx3m3_hgtjstktffs80000gn/T/ipykernel_84425/1977979249.py:24: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  label4 = pd.read_csv(\"./data/2020Q4_DGD.csv\", \\\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"./data/dsc_fc_summed_spectra_2020_v01.csv\", \\\n",
    "delimiter = ',', parse_dates=[0], na_values='0', \\\n",
    "infer_datetime_format=True, \\\n",
    "header = None)\n",
    "\n",
    "label1 = pd.read_csv(\"./data/2020Q1_DGD.csv\", \\\n",
    "delimiter = ',', parse_dates=[0], \\\n",
    "infer_datetime_format=True, \\\n",
    "header = None)\n",
    "\n",
    "label2 = pd.read_csv(\"./data/2020Q2_DGD.csv\", \\\n",
    "delimiter = ',', parse_dates=[0], \\\n",
    "infer_datetime_format=True, \\\n",
    "header = None)\n",
    "\n",
    "label3 = pd.read_csv(\"./data/2020Q3_DGD.csv\", \\\n",
    "delimiter = ',', parse_dates=[0], \\\n",
    "infer_datetime_format=True, \\\n",
    "header = None)\n",
    "\n",
    "label4 = pd.read_csv(\"./data/2020Q4_DGD.csv\", \\\n",
    "delimiter = ',', parse_dates=[0], \\\n",
    "infer_datetime_format=True, \\\n",
    "header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.concat([label1, label2, label3, label4], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna('0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:, 1:49] = data.iloc[:, 1:49].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "grouped_by_day = data.groupby(data.iloc[:, 0].dt.date)\n",
    "day_dataframes = [group for _, group in grouped_by_day]\n",
    "\n",
    "filtered_data0003 = []\n",
    "\n",
    "filtered_data0306 = []\n",
    "\n",
    "filtered_data0609 = []\n",
    "\n",
    "filtered_data0912 = []\n",
    "\n",
    "filtered_data1215 = []\n",
    "\n",
    "filtered_data1518 = []\n",
    "\n",
    "filtered_data1821 = []\n",
    "\n",
    "filtered_data2123 = []\n",
    "\n",
    "counter = 0\n",
    "for day_df in day_dataframes:\n",
    "    filtered_data0003.append(day_df[day_df.iloc[:, 0].dt.hour.between(0, 2)])\n",
    "\n",
    "    filtered_data0306.append(day_df[day_df.iloc[:, 0].dt.hour.between(3, 5)])\n",
    "\n",
    "    filtered_data0609.append(day_df[day_df.iloc[:, 0].dt.hour.between(6, 8)])\n",
    "\n",
    "    filtered_data0912.append(day_df[day_df.iloc[:, 0].dt.hour.between(9, 11)])\n",
    "\n",
    "    filtered_data1215.append(day_df[day_df.iloc[:, 0].dt.hour.between(12, 14)])\n",
    "\n",
    "    filtered_data1518.append(day_df[day_df.iloc[:, 0].dt.hour.between(15, 17)])\n",
    "\n",
    "    filtered_data1821.append(day_df[day_df.iloc[:, 0].dt.hour.between(18, 20)])\n",
    "\n",
    "    filtered_data2123.append(day_df[day_df.iloc[:, 0].dt.hour.between(21, 23)])\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(311):\n",
    "    summed_filtered_data0003[i] = filtered_data0003[i].iloc[:, 1:49].sum(axis=1)\n",
    "    summed_filtered_data0306[i] = filtered_data0306[i].iloc[:, 1:49].sum(axis=1)\n",
    "    summed_filtered_data0609[i] = filtered_data0609[i].iloc[:, 1:49].sum(axis=1)\n",
    "    summed_filtered_data0912[i] = filtered_data0912[i].iloc[:, 1:49].sum(axis=1)\n",
    "    summed_filtered_data1215[i] = filtered_data1215[i].iloc[:, 1:49].sum(axis=1)\n",
    "    summed_filtered_data1518[i] = filtered_data1518[i].iloc[:, 1:49].sum(axis=1)\n",
    "    summed_filtered_data1821[i] = filtered_data1821[i].iloc[:, 1:49].sum(axis=1)\n",
    "    summed_filtered_data2123[i] = filtered_data2123[i].iloc[:, 1:49].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2020-02-25 00:00:00\n",
       "1                 4.04158\n",
       "2               -0.337277\n",
       "3                0.278823\n",
       "4                     0.0\n",
       "5                     0.0\n",
       "6                     0.0\n",
       "7                     0.0\n",
       "8                     0.0\n",
       "9                     0.0\n",
       "10                    0.0\n",
       "11                    0.0\n",
       "12                    0.0\n",
       "13                    0.0\n",
       "14                    0.0\n",
       "15                    0.0\n",
       "16                    0.0\n",
       "17                    0.0\n",
       "18                    0.0\n",
       "19                    0.0\n",
       "20                    0.0\n",
       "21                    0.0\n",
       "22                    0.0\n",
       "23                    0.0\n",
       "24                    0.0\n",
       "25                    0.0\n",
       "26                    0.0\n",
       "27                    0.0\n",
       "28                    0.0\n",
       "29                    0.0\n",
       "30                    0.0\n",
       "31                    0.0\n",
       "32                    0.0\n",
       "33                    0.0\n",
       "34                    0.0\n",
       "35                    0.0\n",
       "36                    0.0\n",
       "37                    0.0\n",
       "38                    0.0\n",
       "39                    0.0\n",
       "40                    0.0\n",
       "41                    0.0\n",
       "42                    0.0\n",
       "43                    0.0\n",
       "44                    0.0\n",
       "45                    0.0\n",
       "46                    0.0\n",
       "47                    0.0\n",
       "48                    0.0\n",
       "49                      0\n",
       "50                      0\n",
       "51                      0\n",
       "52                      0\n",
       "53                      0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data0003[0].iloc[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val1 = [0] * 311\n",
    "min_val2 = [0] * 311\n",
    "min_val3 = [0] * 311\n",
    "min_val4 = [0] * 311\n",
    "min_val5 = [0] * 311\n",
    "min_val6 = [0] * 311\n",
    "min_val7 = [0] * 311\n",
    "min_val8 = [0] * 311\n",
    "\n",
    "for i in range(311):\n",
    "    maxi = 0\n",
    "    count = 0\n",
    "    maxindex = 0\n",
    "    for df in summed_filtered_data0003[i]:\n",
    "        count += 1\n",
    "        if df > maxi:\n",
    "            maxi = df\n",
    "            min_val1[i] = filtered_data0003[i].iloc[count - 1, :] \n",
    "    maxi = 0\n",
    "    count = 0\n",
    "    maxindex = 0\n",
    "    for df in summed_filtered_data0306[i]:\n",
    "        count += 1\n",
    "        if df > maxi:\n",
    "            maxi = df\n",
    "            min_val2[i] = filtered_data0306[i].iloc[count - 1, :]\n",
    "    maxi = 0\n",
    "    count = 0\n",
    "    maxindex = 0\n",
    "    for df in summed_filtered_data0609[i]:\n",
    "        count += 1\n",
    "        if df > maxi:\n",
    "            maxi = df\n",
    "            min_val3[i] = filtered_data0609[i].iloc[count - 1, :]\n",
    "    maxi = 0\n",
    "    count = 0\n",
    "    maxindex = 0\n",
    "    for df in summed_filtered_data0912[i]:\n",
    "        count += 1\n",
    "        if df > maxi:\n",
    "            maxi = df\n",
    "            min_val4[i] = filtered_data0912[i].iloc[count - 1, :]\n",
    "    maxi = 0\n",
    "    count = 0\n",
    "    maxindex = 0\n",
    "    for df in summed_filtered_data1215[i]:\n",
    "        count += 1\n",
    "        if df > maxi:\n",
    "            maxi = df\n",
    "            min_val5[i] = filtered_data1215[i].iloc[count - 1, :] \n",
    "    maxi = 0\n",
    "    count = 0\n",
    "    maxindex = 0\n",
    "    for df in summed_filtered_data1518[i]:\n",
    "        count += 1\n",
    "        if df > maxi:\n",
    "            maxi = df\n",
    "            min_val6[i] = filtered_data1518[i].iloc[count - 1, :] \n",
    "    maxi = 0\n",
    "    count = 0\n",
    "    maxindex = 0\n",
    "    for df in summed_filtered_data1821[i]:\n",
    "        count += 1\n",
    "        if df > maxi:\n",
    "            maxi = df\n",
    "            min_val7[i] = filtered_data1821[i].iloc[count - 1, :] \n",
    "    maxi = 0\n",
    "    count = 0\n",
    "    maxindex = 0\n",
    "    for df in summed_filtered_data2123[i]:\n",
    "        count += 1\n",
    "        if df > maxi:\n",
    "            maxi = df\n",
    "            min_val8[i] = filtered_data2123[i].iloc[count - 1, :] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tx/xsb7n6wx3m3_hgtjstktffs80000gn/T/ipykernel_84425/632357542.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  min_val1 = pd.DataFrame(np.array(min_val1))\n",
      "/var/folders/tx/xsb7n6wx3m3_hgtjstktffs80000gn/T/ipykernel_84425/632357542.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  min_val2 = pd.DataFrame(np.array(min_val2))\n",
      "/var/folders/tx/xsb7n6wx3m3_hgtjstktffs80000gn/T/ipykernel_84425/632357542.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  min_val3 = pd.DataFrame(np.array(min_val3))\n",
      "/var/folders/tx/xsb7n6wx3m3_hgtjstktffs80000gn/T/ipykernel_84425/632357542.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  min_val4 = pd.DataFrame(np.array(min_val4))\n",
      "/var/folders/tx/xsb7n6wx3m3_hgtjstktffs80000gn/T/ipykernel_84425/632357542.py:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  min_val5 = pd.DataFrame(np.array(min_val5))\n",
      "/var/folders/tx/xsb7n6wx3m3_hgtjstktffs80000gn/T/ipykernel_84425/632357542.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  min_val6 = pd.DataFrame(np.array(min_val6))\n",
      "/var/folders/tx/xsb7n6wx3m3_hgtjstktffs80000gn/T/ipykernel_84425/632357542.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  min_val7 = pd.DataFrame(np.array(min_val7))\n",
      "/var/folders/tx/xsb7n6wx3m3_hgtjstktffs80000gn/T/ipykernel_84425/632357542.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  min_val8 = pd.DataFrame(np.array(min_val8))\n"
     ]
    }
   ],
   "source": [
    "min_val1 = pd.DataFrame(np.array(min_val1))\n",
    "min_val2 = pd.DataFrame(np.array(min_val2))\n",
    "min_val3 = pd.DataFrame(np.array(min_val3))\n",
    "min_val4 = pd.DataFrame(np.array(min_val4))\n",
    "min_val5 = pd.DataFrame(np.array(min_val5))\n",
    "min_val6 = pd.DataFrame(np.array(min_val6))\n",
    "min_val7 = pd.DataFrame(np.array(min_val7))\n",
    "min_val8 = pd.DataFrame(np.array(min_val8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/nasa/lib/python3.11/site-packages/pandas/core/indexes/range.py:345\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 345\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_range\u001b[39m.\u001b[39mindex(new_key)\n\u001b[1;32m    346\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[0;31mValueError\u001b[0m: 1 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/yerassyl/dev/nasa/sortmaxmin.ipynb Cell 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yerassyl/dev/nasa/sortmaxmin.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39msum\u001b[39m \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yerassyl/dev/nasa/sortmaxmin.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m311\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yerassyl/dev/nasa/sortmaxmin.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39msum\u001b[39m\u001b[39m.\u001b[39mappend(([min_val1[i], min_val2[i], min_val3[i], min_val4[i], min_val5[i], min_val6[i], min_val7[i], min_val8[i]] ))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yerassyl/dev/nasa/sortmaxmin.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39msum\u001b[39m[i] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(\u001b[39msum\u001b[39m[i])\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yerassyl/dev/nasa/sortmaxmin.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m sorted_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([\u001b[39msum\u001b[39m])\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/nasa/lib/python3.11/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/nasa/lib/python3.11/site-packages/pandas/core/indexes/range.py:347\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_range\u001b[39m.\u001b[39mindex(new_key)\n\u001b[1;32m    346\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 347\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Hashable):\n\u001b[1;32m    349\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "sum = []\n",
    "\n",
    "for i in range(311):\n",
    "    sum.append(([min_val1[i], min_val2[i], min_val3[i], min_val4[i], min_val5[i], min_val6[i], min_val7[i], min_val8[i]] ))\n",
    "    sum[i] = pd.DataFrame(sum[i]).astype(str)\n",
    "\n",
    "sorted_df = pd.concat([sum]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nasa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
